{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qinhui Xu 09/19/2018\n",
    "\n",
    "#### Data Source: https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned in dealing with imbalance step shows, I will prepare two dataset - one come from cluster based undersampling - the other one come from only SMOTE method.\n",
    "\n",
    "I will use following different models to make predictions:\n",
    "\n",
    "1. Logistic Regression\n",
    "2. Gradient Boosting Machine\n",
    "3. Random Forest Model\n",
    "4. XGBoost\n",
    "5. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiffany Xu\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score,accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing based on Data Exploration / Feature Engineering\n",
    "df = pd.read_csv(\"C:/Users/Tiffany Xu/Documents/MachineLearningStudy/DeepLearning/creditcard.csv\")\n",
    "\n",
    "df['V1_'] = df.V1.map(lambda x: 1 if x < -3 else 0)\n",
    "df['V2_'] = df.V2.map(lambda x: 1 if x > 2.5 else 0)\n",
    "df['V3_'] = df.V3.map(lambda x: 1 if x < -4 else 0)\n",
    "df['V4_'] = df.V4.map(lambda x: 1 if x > 2.5 else 0)\n",
    "df['V5_'] = df.V5.map(lambda x: 1 if x < -4.5 else 0)\n",
    "df['V6_'] = df.V6.map(lambda x: 1 if x < -2.5 else 0)\n",
    "df['V7_'] = df.V7.map(lambda x: 1 if x < -3 else 0)\n",
    "df['V9_'] = df.V9.map(lambda x: 1 if x < -2 else 0)\n",
    "df['V10_'] = df.V10.map(lambda x: 1 if x < -2.5 else 0)\n",
    "df['V11_'] = df.V11.map(lambda x: 1 if x > 2 else 0)\n",
    "df['V12_'] = df.V12.map(lambda x: 1 if x < -2 else 0)\n",
    "df['V14_'] = df.V14.map(lambda x: 1 if x < -2.5 else 0)\n",
    "df['V16_'] = df.V16.map(lambda x: 1 if x < -2 else 0)\n",
    "df['V17_'] = df.V17.map(lambda x: 1 if x < -2 else 0)\n",
    "df['V18_'] = df.V18.map(lambda x: 1 if x < -2 else 0)\n",
    "df['V19_'] = df.V19.map(lambda x: 1 if x > 1.5 else 0)\n",
    "df['V21_'] = df.V21.map(lambda x: 1 if x > 0.6 else 0)\n",
    "\n",
    "df['normalized_amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df = df.drop(['Amount','Time'], axis=1)\n",
    "\n",
    "df_nn = df\n",
    "df = df.drop(['V28','V27','V26','V25','V24','V23','V22','V20','V15','V13','V8'], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cluster Based on Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode)\n",
      "  Starting server from C:\\Users\\Tiffany Xu\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\TIFFAN~1\\AppData\\Local\\Temp\\tmpc22jfn45\n",
      "  JVM stdout: C:\\Users\\TIFFAN~1\\AppData\\Local\\Temp\\tmpc22jfn45\\h2o_Tiffany_Xu_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\TIFFAN~1\\AppData\\Local\\Temp\\tmpc22jfn45\\h2o_Tiffany_Xu_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>06 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 4 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_Tiffany_Xu_mvrztd</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.492 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------\n",
       "H2O cluster uptime:         06 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.2\n",
       "H2O cluster version age:    3 months and 4 days\n",
       "H2O cluster name:           H2O_from_python_Tiffany_Xu_mvrztd\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.492 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  ---------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "kmeans Model Build progress: |████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "##### K-mean Cluster Based on Undersampling\n",
    "import h2o\n",
    "h2o.init()\n",
    "import imp\n",
    "from h2o.estimators.kmeans import H2OKMeansEstimator\n",
    "\n",
    "df_notfraud = df[df[\"Class\"]==0]\n",
    "df_fraud = df[df[\"Class\"]==1]\n",
    "\n",
    "df_kmeans_notfraud = df_notfraud.drop(['Class'], axis=1)\n",
    "hf = h2o.H2OFrame(df_kmeans_notfraud)\n",
    "cls = H2OKMeansEstimator(k=len(df_fraud), standardize=True)\n",
    "cls.train(x=hf.columns, training_frame=hf)\n",
    "\n",
    "df_centers = pd.DataFrame(cls.centers())\n",
    "df_centers.columns = hf.columns\n",
    "df_centers[\"Class\"] = 0\n",
    "df_kmeans_undersample = pd.concat([df_centers,df_fraud],axis=0)\n",
    "\n",
    "X_Kmeans_under = df_kmeans_undersample.loc[:,df_kmeans_undersample.columns != 'Class']\n",
    "y_Kmeans_under = df_kmeans_undersample.loc[:,df_kmeans_undersample.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_Kmenas = pd.DataFrame(X_Kmeans_under,columns = df_kmeans_notfraud.columns)\n",
    "df_Y_Kmenas = pd.DataFrame(y_Kmeans_under,columns = [\"Class\"])\n",
    "df_Kmeans = pd.concat([df_X_Kmenas,df_Y_Kmenas],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>...</th>\n",
       "      <th>V11_</th>\n",
       "      <th>V12_</th>\n",
       "      <th>V14_</th>\n",
       "      <th>V16_</th>\n",
       "      <th>V17_</th>\n",
       "      <th>V18_</th>\n",
       "      <th>V19_</th>\n",
       "      <th>V21_</th>\n",
       "      <th>normalized_amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.727143</td>\n",
       "      <td>0.723674</td>\n",
       "      <td>0.562859</td>\n",
       "      <td>-0.306942</td>\n",
       "      <td>0.588354</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.448408</td>\n",
       "      <td>-0.263796</td>\n",
       "      <td>-0.451045</td>\n",
       "      <td>-0.254869</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.318390e-16</td>\n",
       "      <td>4.996004e-16</td>\n",
       "      <td>-1.526557e-16</td>\n",
       "      <td>4.649059e-16</td>\n",
       "      <td>-3.382711e-17</td>\n",
       "      <td>3.764350e-16</td>\n",
       "      <td>-5.134781e-16</td>\n",
       "      <td>8.326673e-16</td>\n",
       "      <td>-0.223390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-35.548539</td>\n",
       "      <td>-31.850484</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>15.304184</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>-3.872425</td>\n",
       "      <td>-12.005487</td>\n",
       "      <td>6.853897</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>102.362243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-36.802320</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-20.645794</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>-20.672064</td>\n",
       "      <td>7.694002</td>\n",
       "      <td>24.956587</td>\n",
       "      <td>-2.687312</td>\n",
       "      <td>-8.423404</td>\n",
       "      <td>1.186360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>78.235272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-6.605265</td>\n",
       "      <td>16.491217</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-19.399981</td>\n",
       "      <td>6.967698</td>\n",
       "      <td>9.537780</td>\n",
       "      <td>3.089395</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.451791</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.904340</td>\n",
       "      <td>12.793880</td>\n",
       "      <td>-7.888739</td>\n",
       "      <td>0.512373</td>\n",
       "      <td>-7.661829</td>\n",
       "      <td>16.614054</td>\n",
       "      <td>-31.764946</td>\n",
       "      <td>-6.290730</td>\n",
       "      <td>-14.741096</td>\n",
       "      <td>-3.038237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.645814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          V1         V2         V3         V4          V5         V6  \\\n",
       "0  -0.727143   0.723674   0.562859  -0.306942    0.588354   0.002418   \n",
       "1 -35.548539 -31.850484 -48.325589  15.304184 -113.743307  73.301626   \n",
       "2 -36.802320 -63.344698 -20.645794  16.715537  -20.672064   7.694002   \n",
       "3 -56.407510 -72.715728  -6.605265  16.491217   34.801666 -26.160506   \n",
       "4 -14.904340  12.793880  -7.888739   0.512373   -7.661829  16.614054   \n",
       "\n",
       "           V7        V9        V10       V11  ...            V11_  \\\n",
       "0    0.448408 -0.263796  -0.451045 -0.254869  ...   -1.318390e-16   \n",
       "1  120.589494 -3.872425 -12.005487  6.853897  ...    1.000000e+00   \n",
       "2   24.956587 -2.687312  -8.423404  1.186360  ...    0.000000e+00   \n",
       "3  -19.399981  6.967698   9.537780  3.089395  ...    1.000000e+00   \n",
       "4  -31.764946 -6.290730 -14.741096 -3.038237  ...    0.000000e+00   \n",
       "\n",
       "           V12_          V14_          V16_          V17_          V18_  \\\n",
       "0  4.996004e-16 -1.526557e-16  4.649059e-16 -3.382711e-17  3.764350e-16   \n",
       "1  1.000000e+00  1.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00   \n",
       "2  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "3  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "4  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "\n",
       "           V19_          V21_  normalized_amount  Class  \n",
       "0 -5.134781e-16  8.326673e-16          -0.223390      0  \n",
       "1  1.000000e+00  0.000000e+00         102.362243      0  \n",
       "2  0.000000e+00  1.000000e+00          78.235272      0  \n",
       "3  1.000000e+00  0.000000e+00           4.451791      0  \n",
       "4  0.000000e+00  0.000000e+00           1.645814      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Kmeans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SMOTE: Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiffany Xu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "##### SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df_features = df.drop(['Class'], axis=1)\n",
    "df_target = df[\"Class\"]\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio=1.0)\n",
    "x_res,y_res = sm.fit_sample(df_features,df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_SMOTE = pd.DataFrame(x_res,columns = df_kmeans_notfraud.columns)\n",
    "df_Y_SMOTE = pd.DataFrame(y_res,columns = [\"Class\"])\n",
    "df_SMOTE = pd.concat([df_X_SMOTE,df_Y_SMOTE],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>...</th>\n",
       "      <th>V11_</th>\n",
       "      <th>V12_</th>\n",
       "      <th>V14_</th>\n",
       "      <th>V16_</th>\n",
       "      <th>V17_</th>\n",
       "      <th>V18_</th>\n",
       "      <th>V19_</th>\n",
       "      <th>V21_</th>\n",
       "      <th>normalized_amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V9       V10       V11  ...    V11_  V12_  V14_  V16_  V17_  V18_  \\\n",
       "0  0.363787  0.090794 -0.551600  ...     0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1 -0.255425 -0.166974  1.612727  ...     0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2 -1.514654  0.207643  0.624501  ...     0.0   0.0   0.0   1.0   0.0   0.0   \n",
       "3 -1.387024 -0.054952 -0.226487  ...     0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4  0.817739  0.753074 -0.822843  ...     0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "   V19_  V21_  normalized_amount  Class  \n",
       "0   0.0   0.0           0.244964      0  \n",
       "1   0.0   0.0          -0.342475      0  \n",
       "2   0.0   0.0           1.160686      0  \n",
       "3   0.0   0.0           0.140534      0  \n",
       "4   0.0   0.0          -0.073403      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SMOTE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans: Logistic Regression Sensitivity/Recall is: 0.9407894736842105\n",
      "Kmeans: Logistic Regression Specificity is: 0.9375\n"
     ]
    }
   ],
   "source": [
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_Kmeans_under,y_Kmeans_under,test_size = 0.3, random_state = 12)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_under_train,y_under_train)\n",
    "y_pred = lr.predict(X_under_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_under_test, y_pred).ravel()\n",
    "print(\"Kmeans: Logistic Regression Sensitivity/Recall is:\",tp/(tp+fn))\n",
    "print(\"Kmeans: Logistic Regression Specificity is:\",tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: Logistic Regression Sensitivity/Recall is: 0.9192237421530965\n",
      "SMOTE: Logistic Regression Specificity is: 0.9706824716859339\n"
     ]
    }
   ],
   "source": [
    "x_train_res, x_val_res, y_train_res, y_val_res = train_test_split(x_res,\n",
    "                                                    y_res,\n",
    "                                                    test_size = .3,\n",
    "                                                    random_state=12)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train_res,y_train_res)\n",
    "y_pred = lr.predict(x_val_res)\n",
    "tn, fp, fn, tp = confusion_matrix(y_val_res, y_pred).ravel()\n",
    "print(\"SMOTE: Logistic Regression Sensitivity/Recall is:\",tp/(tp+fn))\n",
    "print(\"SMOTE: Logistic Regression Specificity is:\",tn/(tn+fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#### Kmeans H2OFrame\n",
    "hf_Kmeans = h2o.H2OFrame(df_Kmeans)\n",
    "hf_Kmeans[\"Class\"] = hf_Kmeans[\"Class\"].asfactor()\n",
    "\n",
    "train_Kmeans, valid_Kmeans = hf_Kmeans.split_frame(\n",
    "    ratios=[0.7], \n",
    "    seed=12, \n",
    "    destination_frames=['train_Kmeans.hex','valid_Kmeans.hex']\n",
    ")\n",
    "\n",
    "#### SMOTE H2OFrame\n",
    "hf_SMOTE = h2o.H2OFrame(df_SMOTE)\n",
    "hf_SMOTE[\"Class\"] = hf_SMOTE[\"Class\"].asfactor()\n",
    "\n",
    "train_SMOTE, valid_SMOTE = hf_SMOTE.split_frame(\n",
    "    ratios=[0.7], \n",
    "    seed=12, \n",
    "    destination_frames=['train_SMOTE.hex','valid_SMOTE.hex']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5979462663399188: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>144.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.04</td>\n",
       "<td> (6.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>2.0</td>\n",
       "<td>144.0</td>\n",
       "<td>0.0137</td>\n",
       "<td> (2.0/146.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>146.0</td>\n",
       "<td>150.0</td>\n",
       "<td>0.027</td>\n",
       "<td> (8.0/296.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      144  6    0.04     (6.0/150.0)\n",
       "1      2    144  0.0137   (2.0/146.0)\n",
       "Total  146  150  0.027    (8.0/296.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = hf_Kmeans.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(\n",
    "  ntrees = 10000,                                                            \n",
    "  learn_rate = 0.01,                                                         \n",
    "  stopping_rounds = 20, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "  sample_rate = 0.8,\n",
    "  col_sample_rate = 0.8,\n",
    "  seed = 12,\n",
    "  score_tree_interval = 10)\n",
    "\n",
    "gbm.train(x=predictors, y=response, training_frame=train_Kmeans,\n",
    "         validation_frame = valid_Kmeans)\n",
    "\n",
    "perf = gbm.model_performance(valid = True)\n",
    "gbm.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans: GBM Sensitivity/Recall is: 0.96\n",
      "Kmeans: GBM Specificity is: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Kmeans: GBM Sensitivity/Recall is:\",144/150)\n",
    "print(\"Kmeans: GBM Specificity is:\",144/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.4556398035662969: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>84629.0</td>\n",
       "<td>407.0</td>\n",
       "<td>0.0048</td>\n",
       "<td> (407.0/85036.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>274.0</td>\n",
       "<td>85158.0</td>\n",
       "<td>0.0032</td>\n",
       "<td> (274.0/85432.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>84903.0</td>\n",
       "<td>85565.0</td>\n",
       "<td>0.004</td>\n",
       "<td> (681.0/170468.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  ----------------\n",
       "0      84629  407    0.0048   (407.0/85036.0)\n",
       "1      274    85158  0.0032   (274.0/85432.0)\n",
       "Total  84903  85565  0.004    (681.0/170468.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = hf_SMOTE.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "gbm = H2OGradientBoostingEstimator(\n",
    "  ntrees = 10000,                                               \n",
    "  learn_rate = 0.01,                                                         \n",
    "  stopping_rounds = 20, stopping_tolerance = 1e-4, stopping_metric = \"AUC\", \n",
    "  sample_rate = 0.8,\n",
    "  col_sample_rate = 0.8,\n",
    "  seed = 12,\n",
    "  score_tree_interval = 10)\n",
    "\n",
    "gbm.train(x=predictors, y=response, training_frame=train_SMOTE,\n",
    "         validation_frame = valid_SMOTE)\n",
    "\n",
    "perf = gbm.model_performance(valid = True)\n",
    "gbm.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: GBM Sensitivity/Recall is: 0.9952433822240402\n",
      "SMOTE: GBM Specificity is: 0.9952137918058234\n"
     ]
    }
   ],
   "source": [
    "print(\"SMOTE: GBM Sensitivity/Recall is:\",85158/85565)\n",
    "print(\"SMOTE: GBM Specificity is:\",84629/85036)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.random_forest import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6170212765957447: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>146.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0267</td>\n",
       "<td> (4.0/150.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>7.0</td>\n",
       "<td>139.0</td>\n",
       "<td>0.0479</td>\n",
       "<td> (7.0/146.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>153.0</td>\n",
       "<td>143.0</td>\n",
       "<td>0.0372</td>\n",
       "<td> (11.0/296.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      146  4    0.0267   (4.0/150.0)\n",
       "1      7    139  0.0479   (7.0/146.0)\n",
       "Total  153  143  0.0372   (11.0/296.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = hf_Kmeans.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "rf_kmeans = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_kmeans\",\n",
    "    ntrees = 10000, \n",
    "    stopping_rounds=20,\n",
    "    score_each_iteration=True,\n",
    "    seed=12)\n",
    "\n",
    "rf_kmeans.train(x=predictors, y=response, training_frame=train_Kmeans,\n",
    "         validation_frame = valid_Kmeans)\n",
    "\n",
    "perf = rf_kmeans.model_performance(valid = True)\n",
    "rf_kmeans.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans: RFM Sensitivity/Recall is: 0.9788732394366197\n",
      "Kmeans: RFM Specificity is: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Kmeans: RFM Sensitivity/Recall is:\",139/143)\n",
    "print(\"Kmeans: RFM Specificity is:\",146/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.5470289682056039: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>85020.0</td>\n",
       "<td>16.0</td>\n",
       "<td>0.0002</td>\n",
       "<td> (16.0/85036.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11.0</td>\n",
       "<td>85421.0</td>\n",
       "<td>0.0001</td>\n",
       "<td> (11.0/85432.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>85031.0</td>\n",
       "<td>85437.0</td>\n",
       "<td>0.0002</td>\n",
       "<td> (27.0/170468.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  ---------------\n",
       "0      85020  16     0.0002   (16.0/85036.0)\n",
       "1      11     85421  0.0001   (11.0/85432.0)\n",
       "Total  85031  85437  0.0002   (27.0/170468.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = hf_Kmeans.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "rf_SMOTE = H2ORandomForestEstimator(\n",
    "    model_id=\"rf_SMOTE\",\n",
    "    ntrees = 10000,      \n",
    "    stopping_rounds=20,\n",
    "    score_each_iteration=True,\n",
    "    seed=12)\n",
    "\n",
    "rf_SMOTE.train(x=predictors, y=response, training_frame=train_SMOTE,\n",
    "         validation_frame = valid_SMOTE)\n",
    "\n",
    "perf = rf_SMOTE.model_performance(valid = True)\n",
    "rf_SMOTE.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: RFM Sensitivity/Recall is: 0.9998127275068179\n",
      "SMOTE: RFM Specificity is: 0.9998118443953149\n"
     ]
    }
   ],
   "source": [
    "print(\"SMOTE: RFM Sensitivity/Recall is:\", 85421/85437)\n",
    "print(\"SMOTE: RFM Specificity is:\",85020/85036)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2OXGBoostEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "H2OResponseError",
     "evalue": "Server error water.exceptions.H2ONotFoundArgumentException:\n  Error: POST /3/ModelBuilders/xgboost not found\n  Request: POST /3/ModelBuilders/xgboost\n    data: {'model_id': 'xgb_Kmeans', 'ntrees': '10000', 'learn_rate': '0.005', 'sample_rate': '0.1', 'col_sample_rate': '0.8', 'max_depth': '5', 'nfolds': '3', 'keep_cross_validation_predictions': 'True', 'stopping_rounds': '10', 'seed': '12', 'distribution': 'bernoulli', 'training_frame': 'train_Kmeans.hex', 'validation_frame': 'valid_Kmeans.hex', 'response_column': 'Class'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-079df1207b9f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     distribution = 'bernoulli')\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mxgb_Kmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_Kmeans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_Kmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\estimators\\estimator_base.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, max_runtime_secs, ignored_columns, model_id, verbose)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mrest_ver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_rest_version\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"_rest_version\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparms\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mmodel_builder_json\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"POST /%d/ModelBuilders/%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrest_ver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2OJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_builder_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgo\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" Model Build\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\h2o.py\u001b[0m in \u001b[0;36mapi\u001b[1;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;31m# type checks are performed in H2OConnection class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0m_check_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mh2oconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\backend\\connection.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                     auth=self._auth, verify=self._verify_ssl_cert, proxies=self._proxies)\n\u001b[0;32m    401\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_end_transaction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h2o\\backend\\connection.py\u001b[0m in \u001b[0;36m_process_response\u001b[1;34m(response, save_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[1;31m# Client errors (400 = \"Bad Request\", 404 = \"Not Found\", 412 = \"Precondition Failed\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m404\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m412\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mH2OErrorV3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH2OModelBuilderErrorV3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mH2OResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;31m# Server errors (notably 500 = \"Server Error\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mH2OResponseError\u001b[0m: Server error water.exceptions.H2ONotFoundArgumentException:\n  Error: POST /3/ModelBuilders/xgboost not found\n  Request: POST /3/ModelBuilders/xgboost\n    data: {'model_id': 'xgb_Kmeans', 'ntrees': '10000', 'learn_rate': '0.005', 'sample_rate': '0.1', 'col_sample_rate': '0.8', 'max_depth': '5', 'nfolds': '3', 'keep_cross_validation_predictions': 'True', 'stopping_rounds': '10', 'seed': '12', 'distribution': 'bernoulli', 'training_frame': 'train_Kmeans.hex', 'validation_frame': 'valid_Kmeans.hex', 'response_column': 'Class'}\n"
     ]
    }
   ],
   "source": [
    "predictors = hf_Kmeans.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "xgb_Kmeans = H2OXGBoostEstimator(\n",
    "    model_id=\"xgb_Kmeans\",\n",
    "    ntrees = 10000,\n",
    "    learn_rate = 0.005,\n",
    "    sample_rate = 0.1, \n",
    "    col_sample_rate = 0.8,\n",
    "    max_depth = 5,\n",
    "    nfolds = 3,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    stopping_rounds = 10,\n",
    "    seed = 12,\n",
    "    distribution = 'bernoulli')\n",
    "\n",
    "xgb_Kmeans.train(x=predictors, y=response, training_frame=train_Kmeans, validation_frame = valid_Kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kmeans: XGBoost Sensitivity/Recall is:\",139/142)\n",
    "print(\"Kmeans: XGBoost Specificity is:\",146/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = hf_SMOTE.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "xgb_SMOTE = H2OXGBoostEstimator(\n",
    "    model_id=\"xgb_SMOTE\",\n",
    "    ntrees = 10000,\n",
    "    learn_rate = 0.005,\n",
    "    sample_rate = 0.1, \n",
    "    col_sample_rate = 0.8,\n",
    "    max_depth = 5,\n",
    "    nfolds = 3,\n",
    "    keep_cross_validation_predictions=True,\n",
    "    stopping_rounds = 10,\n",
    "    seed = 12,\n",
    "    distribution = 'bernoulli')\n",
    "\n",
    "xgb_Kmeans.train(x=predictors, y=response, training_frame=train_SMOTE, validation_frame = valid_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SMOTE: XGBoost Sensitivity/Recall is:\",139/142)\n",
    "print(\"SMOTE: XGBoost Specificity is:\",146/150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "kmeans Model Build progress: |████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "##### K-mean Cluster Based on Undersampling - Neural Network Dataset\n",
    "df_notfraud_nn = df_nn[df_nn[\"Class\"]==0]\n",
    "df_fraud_nn = df_nn[df_nn[\"Class\"]==1]\n",
    "\n",
    "df_kmeans_notfraud_nn = df_notfraud_nn.drop(['Class'], axis=1)\n",
    "hf_nn = h2o.H2OFrame(df_kmeans_notfraud_nn)\n",
    "cls_nn = H2OKMeansEstimator(k=len(df_fraud_nn), standardize=True)\n",
    "cls_nn.train(x=hf_nn.columns, training_frame=hf_nn)\n",
    "\n",
    "df_centers_nn = pd.DataFrame(cls_nn.centers())\n",
    "df_centers_nn.columns = hf_nn.columns\n",
    "df_centers_nn[\"Class\"] = 0\n",
    "df_kmeans_undersample_nn = pd.concat([df_centers_nn,df_fraud_nn],axis=0)\n",
    "\n",
    "X_Kmeans_under_nn = df_kmeans_undersample_nn.loc[:,df_kmeans_undersample_nn.columns != 'Class']\n",
    "y_Kmeans_under_nn = df_kmeans_undersample_nn.loc[:,df_kmeans_undersample_nn.columns == 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_Kmenas_nn = pd.DataFrame(X_Kmeans_under_nn,columns = df_kmeans_notfraud_nn.columns)\n",
    "df_Y_Kmenas_nn = pd.DataFrame(y_Kmeans_under_nn,columns = [\"Class\"])\n",
    "df_Kmeans_nn = pd.concat([df_X_Kmenas_nn,df_Y_Kmenas_nn],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tiffany Xu\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "##### SMOTE\n",
    "df_features_nn = df_nn.drop(['Class'], axis=1)\n",
    "df_target_nn = df_nn[\"Class\"]\n",
    "\n",
    "sm = SMOTE(random_state=12, ratio=1.0)\n",
    "x_res_nn,y_res_nn = sm.fit_sample(df_features_nn,df_target_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_SMOTE_nn = pd.DataFrame(x_res_nn,columns = df_kmeans_notfraud_nn.columns)\n",
    "df_Y_SMOTE_nn = pd.DataFrame(y_res_nn,columns = [\"Class\"])\n",
    "df_SMOTE_nn = pd.concat([df_X_SMOTE_nn,df_Y_SMOTE_nn],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#### Kmeans H2OFrame\n",
    "hf_Kmeans_nn = h2o.H2OFrame(df_Kmeans_nn)\n",
    "hf_Kmeans_nn[\"Class\"] = hf_Kmeans_nn[\"Class\"].asfactor()\n",
    "\n",
    "train_Kmeans_nn, valid_Kmeans_nn = hf_Kmeans_nn.split_frame(\n",
    "    ratios=[0.7], \n",
    "    seed=12, \n",
    "    destination_frames=['train_Kmeans_nn.hex','valid_Kmeans_nn.hex']\n",
    ")\n",
    "\n",
    "#### SMOTE H2OFrame\n",
    "hf_SMOTE_nn = h2o.H2OFrame(df_SMOTE_nn)\n",
    "hf_SMOTE_nn[\"Class\"] = hf_SMOTE_nn[\"Class\"].asfactor()\n",
    "\n",
    "train_SMOTE_nn, valid_SMOTE_nn = hf_SMOTE_nn.split_frame(\n",
    "    ratios=[0.7], \n",
    "    seed=12, \n",
    "    destination_frames=['train_SMOTE_nn.hex','valid_SMOTE_nn.hex']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "predictors = hf_Kmeans_nn.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "nn_Kmeans = H2ODeepLearningEstimator(\n",
    "    model_id=\"nn_Kmeans\",\n",
    "    hidden=[32,32,32],                  ## small network, runs faster\n",
    "    epochs=1000000,                      ## hopefully converges earlier...\n",
    "    score_validation_samples=10000,      ## sample the validation dataset (faster)\n",
    "    stopping_rounds=2,\n",
    "    stopping_metric=\"misclassification\", ## could be \"MSE\",\"logloss\",\"r2\"\n",
    "    stopping_tolerance=0.01,\n",
    "    seed = 12,\n",
    "    distribution = 'bernoulli')\n",
    "\n",
    "nn_Kmeans.train(x=predictors, y=response, training_frame=train_Kmeans_nn, validation_frame = valid_Kmeans_nn)\n",
    "nn_Kmeans.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans: RFM Sensitivity/Recall is: 0.8875\n",
      "Kmeans: RFM Specificity is: 0.88\n"
     ]
    }
   ],
   "source": [
    "print(\"Kmeans: Neural Network Sensitivity/Recall is:\",142/160)\n",
    "print(\"Kmeans: Neural Network Specificity is:\",132/150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 7.396273239463468e-05: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>84929.0</td>\n",
       "<td>107.0</td>\n",
       "<td>0.0013</td>\n",
       "<td> (107.0/85036.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>11741.0</td>\n",
       "<td>73691.0</td>\n",
       "<td>0.1374</td>\n",
       "<td> (11741.0/85432.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>96670.0</td>\n",
       "<td>73798.0</td>\n",
       "<td>0.0695</td>\n",
       "<td> (11848.0/170468.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0      1      Error    Rate\n",
       "-----  -----  -----  -------  ------------------\n",
       "0      84929  107    0.0013   (107.0/85036.0)\n",
       "1      11741  73691  0.1374   (11741.0/85432.0)\n",
       "Total  96670  73798  0.0695   (11848.0/170468.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = hf_SMOTE_nn.columns\n",
    "del predictors[-1]\n",
    "response = \"Class\"\n",
    "\n",
    "nn_SMOTE = H2ODeepLearningEstimator(\n",
    "    model_id=\"nn_SMOTE\",\n",
    "    hidden=[32,32,32],                  ## small network, runs faster\n",
    "    epochs=1000000,                      ## hopefully converges earlier...\n",
    "    #score_validation_samples=10000,      ## sample the validation dataset (faster)\n",
    "    stopping_rounds=2,\n",
    "    stopping_metric=\"misclassification\", ## could be \"MSE\",\"logloss\",\"r2\"\n",
    "    stopping_tolerance=0.01,\n",
    "    seed = 12,\n",
    "    distribution = 'bernoulli')\n",
    "\n",
    "nn_SMOTE.train(x=predictors, y=response, training_frame=train_SMOTE_nn, validation_frame = valid_SMOTE_nn)\n",
    "nn_SMOTE.confusion_matrix(valid= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE: Neural Network Sensitivity/Recall is: 0.9985500962085694\n",
      "SMOTE: Neural Network Specificity is: 0.9987417093936686\n"
     ]
    }
   ],
   "source": [
    "print(\"SMOTE: Neural Network Sensitivity/Recall is:\",73691/73798)\n",
    "print(\"SMOTE: Neural Network Specificity is:\",84929/85036)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Comparsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17e49fff4e0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LR, GBM ,RFM,-XGBoost, NeuralNetwork\n",
    "Recall_Kmeans = [0.94079,0.96,0.97887,0.8875]\n",
    "Recall_SMOTE = [0.91922,0.99524,0.99981,0.99855]\n",
    "df_summary = pd.DataFrame({\"Kmeans\":Recall_Kmeans,\"SMOTE\":Recall_SMOTE})\n",
    "df_summary.index = [\"Logistic Regression\",\"GBM\",\"RFM\",\"NeuralNetwork\"]\n",
    "df_summary.plot.bar(rot = 0,alpha=0.75,)\n",
    "plt.grid(zorder=0)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5),title = \"Recall Rate Comparsion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17e49f79ba8>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LR, GBM ,RFM,-XGBoost, NeuralNetwork\n",
    "Spec_Kmeans = [0.9375,0.96,0.97333,0.88]\n",
    "Spec_SMOTE = [0.97069,0.99521,0.99981,0.99874]\n",
    "df_summary = pd.DataFrame({\"Kmeans\":Spec_Kmeans,\"SMOTE\":Spec_SMOTE})\n",
    "df_summary.index = [\"Logistic Regression\",\"GBM\",\"RFM\",\"NeuralNetwork\"]\n",
    "df_summary.plot.bar(rot = 0,alpha=0.75,)\n",
    "plt.grid(zorder=0)\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5),title = \"Specificity Rate Comparsion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network achieved highest Recall Rate - **0.99855** for dataset based on SMOTE transformation, which also achieved Specificity Rate as high as **0.99874**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
